{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import sent_tokenize,word_tokenize\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.stem import PorterStemmer\n",
    "import string\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA = open('ourData.txt','r').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Set\n",
    "\n",
    "\n",
    "def get_sentences (sentence,text) :\n",
    "   synonyms  = []\n",
    "   antonyms  = []\n",
    "   sentences = []\n",
    "   \n",
    "   punks = string.punctuation  \n",
    "   stopword = stopwords.words()\n",
    "   \n",
    "   ps = PorterStemmer()\n",
    "   words = [ps.stem(word) for word in word_tokenize(sentence.lower())]\n",
    "   for s in words :\n",
    "    if s in punks or s in stopword :\n",
    "      continue\n",
    "    synonyms.append(s)  \n",
    "    syns = wordnet.synsets(s)\n",
    "    for i in syns:\n",
    "        synonyms.append(i.lemmas()[0].name())\n",
    "        if i.lemmas()[0].antonyms() :\n",
    "            antonyms.append(i.lemmas()[0].antonyms()[0].name())\n",
    "            \n",
    "    synonyms = list(set(synonyms))\n",
    "    antonyms = list(set(antonyms))\n",
    "    stk = sent_tokenize(text)\n",
    "    \n",
    "    for sent in stk :\n",
    "        for word in word_tokenize(sent.lower()) :\n",
    "         if word in synonyms  :   \n",
    "           sentences.append(sent)       \n",
    "         if word in antonyms and word_tokenize(sent)[word_tokenize(sent).index(word)-1] == 'not':\n",
    "           sentences.append(sent)         \n",
    "   return list(set(sentences)) ,list(set(synonyms)), list(set(antonyms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_respnse(sentence,data):\n",
    "    most_common = 0\n",
    "    less_common = 0\n",
    "    sent = ''\n",
    "    \n",
    "    sentences, synonyms, antonyms = get_sentences (sentence,data) \n",
    "    \n",
    "    for i in sentences :\n",
    "        temp = 0\n",
    "        wtk = word_tokenize(i)\n",
    "        for j in wtk :  \n",
    "            if j in synonyms or 'not'+j in antonyms :\n",
    "                temp += 1\n",
    "                \n",
    "        if temp >= most_common :      \n",
    "              most_common = temp\n",
    "              sent = i\n",
    "              \n",
    "    return sent           \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "GREETING_INPUTS = (\"hello\", \"hi\", \"greetings\", \"sup\", \"what's up\",\"hey\",)\n",
    "GREETING_RESPONSES = [\"hi\", \"hey\",\"hi there\", \"hello\", \"I am glad! You are talking to me\"]\n",
    "\n",
    "def greeting(sentence):\n",
    "    for word in sentence.split():\n",
    "        if word.lower() in GREETING_INPUTS:\n",
    "            return random.choice(GREETING_RESPONSES)\n",
    "        \n",
    "STOPING_INPUTS = (\"stop\", \"bye\", \"goodbye\")\n",
    "STOPING_RESPONSES = [\"thanks sir see you later\", \"goodbye\", \"bye\"]\n",
    "\n",
    "def stoping(sentence):\n",
    "    for word in sentence.split():\n",
    "        if word.lower() in STOPING_INPUTS:\n",
    "            return random.choice(STOPING_RESPONSES)     \n",
    "\n",
    "NOT_UNDERSTAND_RESPONSES = ['I did not understand', 'I don\\'t know what you mean','I couldn\\'t figure it out']\n",
    "def not_understand (): \n",
    "    return random.choice(NOT_UNDERSTAND_RESPONSES)     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B26 : I'm B26, and it's good to talk to you.\n",
      "-------------------------------\n",
      "User: hi\n",
      "B26: hey\n",
      "User: what is egypt ?\n",
      "B26: Egypt is a country in North Africa.Most of Egypt is desert.The longest river in the world,the Nile,runs through Egypt providing areas of very lush green.\n",
      "User: why the ancient Egyptian civilization was so successful ?\n",
      "B26: The Nile river is thought to be the most important element (part) of why the ancient Egyptian civilization was so successful.\n",
      "User: what is pyramids ?\n",
      "B26: I did not understand\n",
      "User: bye\n",
      "B26: bye\n"
     ]
    }
   ],
   "source": [
    "flag = True\n",
    "print('B26 : I\\'m B26, and it\\'s good to talk to you.')\n",
    "print('-------------------------------')\n",
    "\n",
    "while (flag) :\n",
    "\n",
    "    user_response = input('Augustus :')\n",
    "    print(f'User: {user_response}')\n",
    "    \n",
    "    if (greeting(user_response)) :\n",
    "        print(f'B26: {greeting(user_response)}')\n",
    "        \n",
    "    elif (stoping(user_response)) :\n",
    "        print(f'B26: {stoping(user_response)}')\n",
    "        flag = False\n",
    "    elif (get_respnse(user_response,DATA)) != '' :  \n",
    "          print(f'B26: {get_respnse(user_response,DATA)}')\n",
    "    else :    \n",
    "        print(f'B26: {not_understand()}')\n",
    "    \n",
    "                "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "53d50ed1839d2292cfd39f0644d59e889da85062f836d8db82f8d3a293c0c3a5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
